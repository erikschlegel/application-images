FROM java:openjdk-8-jdk

ENV hadoop_ver 2.7.3
ENV spark_ver 2.1.0
ENV spark_hadoop_ver 2.7

RUN ln -sf /bin/bash /bin/sh

RUN cd /tmp && \
    curl -O http://www.us.apache.org/dist/hadoop/common/hadoop-${hadoop_ver}/hadoop-${hadoop_ver}.tar.gz && \
    curl -O http://www.us.apache.org/dist/spark/spark-${spark_ver}/spark-${spark_ver}-bin-hadoop${spark_hadoop_ver}.tgz && \
    curl -O https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar

RUN mkdir -p /opt && \
    cd /opt && \
    tar -zxf /tmp/hadoop-${hadoop_ver}.tar.gz hadoop-${hadoop_ver}/lib/native && \
    ln -s hadoop-${hadoop_ver} hadoop && \
    echo Hadoop ${hadoop_ver} native libraries installed in /opt/hadoop/lib/native

# Get Spark from US Apache mirror.
RUN mkdir -p /opt && \
    cd /opt && \
    tar -zxf /tmp/spark-${spark_ver}-bin-hadoop${spark_hadoop_ver}.tgz && \
    ln -s spark-${spark_ver}-bin-hadoop${spark_hadoop_ver} spark && \
    echo Spark ${spark_ver} installed in /opt

# Add the GCS connector.
RUN cd /opt/spark/jars && \
    cp /tmp/gcs-connector-latest-hadoop2.jar .

RUN rm -rf /tmp/* && \
    apt-get update && \
    apt-get -y upgrade && \
    apt-get install -y apt-utils python-numpy python-pip maven && \
    curl -sL https://deb.nodesource.com/setup_7.x | bash && \
    apt-get install -y nodejs build-essential && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN pip install boto

#RUN npm install -g apache-spark-node

RUN mvn dependency:get -DrepoUrl=http://repo1.maven.org/maven2 -Dartifact=org.apache.hadoop:hadoop-aws:2.7.2 && \
    mvn dependency:get -DrepoUrl=http://repo1.maven.org/maven2 -Dartifact=com.amazonaws:aws-java-sdk:1.10.34 && \
    mvn dependency:get -DrepoUrl=http://repo1.maven.org/maven2 -Dartifact=org.apache.spark:spark-streaming-kinesis-asl_2.11:2.1.0 && \
    shopt -s globstar && cp /root/.m2/repository/**/*.jar /opt/spark/jars

ADD log4j.properties /opt/spark/conf/log4j.properties
ADD start-common.sh start-worker start-master /
ADD core-site.xml /opt/spark/conf/core-site.xml
ADD spark-defaults.conf /opt/spark/conf/spark-defaults.conf
ENV PATH $PATH:/opt/spark/bin
